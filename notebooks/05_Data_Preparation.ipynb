{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.config import (\n",
    "    SELECTED_DATA_PATH, SEQUENCES_DIR, SCALER_PATH,\n",
    "    TARGET_COLUMN, DATE_COLUMN,\n",
    "    INPUT_SEQ_LEN, OUTPUT_SEQ_LEN,\n",
    "    TRAIN_RATIO, VAL_RATIO, TEST_RATIO,\n",
    "    RANDOM_SEED, set_seed\n",
    ")\n",
    "from src.dataset import create_sequences, train_val_test_split\n",
    "from src.utils import save_numpy, save_pickle\n",
    "\n",
    "# Set random seed\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Input sequence length: {INPUT_SEQ_LEN}\")\n",
    "print(f\"Output sequence length: {OUTPUT_SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d3f00",
   "metadata": {},
   "source": [
    "## 5.1 Load Selected Features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc54991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(SELECTED_DATA_PATH, parse_dates=[DATE_COLUMN])\n",
    "print(f\"Loaded data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature columns (exclude date_time)\n",
    "feature_columns = [c for c in df.columns if c != DATE_COLUMN]\n",
    "print(f\"Feature columns: {len(feature_columns)}\")\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4498fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find target column index\n",
    "target_idx = feature_columns.index(TARGET_COLUMN)\n",
    "print(f\"Target column '{TARGET_COLUMN}' index: {target_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b473e5f",
   "metadata": {},
   "source": [
    "## 5.2 Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data values (without date_time)\n",
    "data = df[feature_columns].values\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split indices\n",
    "n_samples = len(data)\n",
    "train_end = int(n_samples * TRAIN_RATIO)\n",
    "val_end = int(n_samples * (TRAIN_RATIO + VAL_RATIO))\n",
    "\n",
    "print(f\"Total samples: {n_samples:,}\")\n",
    "print(f\"Train: 0 to {train_end:,}\")\n",
    "print(f\"Val: {train_end:,} to {val_end:,}\")\n",
    "print(f\"Test: {val_end:,} to {n_samples:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler on TRAINING data only\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(data[:train_end])\n",
    "\n",
    "# Transform all data\n",
    "data_scaled = scaler.transform(data)\n",
    "\n",
    "print(f\"Data scaled. Min: {data_scaled.min():.4f}, Max: {data_scaled.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613af1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before scaling\n",
    "axes[0].hist(data[:, target_idx], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Traffic Volume - Before Scaling')\n",
    "axes[0].set_xlabel('Value')\n",
    "\n",
    "# After scaling\n",
    "axes[1].hist(data_scaled[:, target_idx], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Traffic Volume - After Scaling')\n",
    "axes[1].set_xlabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6b6df",
   "metadata": {},
   "source": [
    "## 5.3 Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "X, y = create_sequences(\n",
    "    data=data_scaled,\n",
    "    target_idx=target_idx,\n",
    "    input_seq_len=INPUT_SEQ_LEN,\n",
    "    output_seq_len=OUTPUT_SEQ_LEN\n",
    ")\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}  (samples, input_seq_len, n_features)\")\n",
    "print(f\"y shape: {y.shape}  (samples, output_seq_len)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aac540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample sequence\n",
    "sample_idx = 1000\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Input sequence (target column)\n",
    "axes[0].plot(range(INPUT_SEQ_LEN), X[sample_idx, :, target_idx], 'b-o', label='Input')\n",
    "axes[0].set_xlabel('Time Step')\n",
    "axes[0].set_ylabel('Scaled Value')\n",
    "axes[0].set_title(f'Sample {sample_idx}: Input Sequence ({INPUT_SEQ_LEN} steps)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Full sequence (input + output)\n",
    "axes[1].plot(range(INPUT_SEQ_LEN), X[sample_idx, :, target_idx], 'b-o', label='Input')\n",
    "axes[1].plot(range(INPUT_SEQ_LEN, INPUT_SEQ_LEN + OUTPUT_SEQ_LEN), y[sample_idx], 'r-o', label='Target')\n",
    "axes[1].axvline(x=INPUT_SEQ_LEN - 0.5, color='gray', linestyle='--')\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Scaled Value')\n",
    "axes[1].set_title(f'Sample {sample_idx}: Full Sequence (Input + Target)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ed1e6",
   "metadata": {},
   "source": [
    "## 5.4 Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (time-based, no shuffle)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(\n",
    "    X, y,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f710b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify shapes\n",
    "print(\"\\nData Shapes:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_val:   {X_val.shape}\")\n",
    "print(f\"y_val:   {y_val.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "print(f\"y_test:  {y_test.shape}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d942e6c",
   "metadata": {},
   "source": [
    "## 5.5 Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d792d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create sequences directory if not exists\n",
    "os.makedirs(SEQUENCES_DIR, exist_ok=True)\n",
    "\n",
    "# Save sequences\n",
    "save_numpy(X_train, os.path.join(SEQUENCES_DIR, 'X_train.npy'))\n",
    "save_numpy(y_train, os.path.join(SEQUENCES_DIR, 'y_train.npy'))\n",
    "save_numpy(X_val, os.path.join(SEQUENCES_DIR, 'X_val.npy'))\n",
    "save_numpy(y_val, os.path.join(SEQUENCES_DIR, 'y_val.npy'))\n",
    "save_numpy(X_test, os.path.join(SEQUENCES_DIR, 'X_test.npy'))\n",
    "save_numpy(y_test, os.path.join(SEQUENCES_DIR, 'y_test.npy'))\n",
    "\n",
    "# Save scaler\n",
    "save_pickle(scaler, SCALER_PATH)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'input_seq_len': INPUT_SEQ_LEN,\n",
    "    'output_seq_len': OUTPUT_SEQ_LEN,\n",
    "    'n_features': X_train.shape[2],\n",
    "    'target_idx': target_idx,\n",
    "    'feature_columns': feature_columns,\n",
    "    'train_samples': len(X_train),\n",
    "    'val_samples': len(X_val),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "from src.utils import save_json\n",
    "save_json(metadata, os.path.join(SEQUENCES_DIR, 'metadata.json'))\n",
    "\n",
    "print(\"\\nAll data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c06aa",
   "metadata": {},
   "source": [
    "## 5.6 Verify Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify\n",
    "X_train_loaded = np.load(os.path.join(SEQUENCES_DIR, 'X_train.npy'))\n",
    "y_train_loaded = np.load(os.path.join(SEQUENCES_DIR, 'y_train.npy'))\n",
    "\n",
    "print(f\"Loaded X_train shape: {X_train_loaded.shape}\")\n",
    "print(f\"Loaded y_train shape: {y_train_loaded.shape}\")\n",
    "print(f\"\\nData matches: {np.allclose(X_train, X_train_loaded) and np.allclose(y_train, y_train_loaded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c72d02",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Data Preparation completed:**\n",
    "1. ✅ Loaded selected features data\n",
    "2. ✅ Scaled data using MinMaxScaler (fit on train only)\n",
    "3. ✅ Created input/output sequences\n",
    "4. ✅ Split into train/val/test (time-based)\n",
    "5. ✅ Saved sequences as numpy arrays\n",
    "6. ✅ Saved scaler for inverse transform\n",
    "\n",
    "**Data Summary:**\n",
    "- Input sequence length: 24 timesteps\n",
    "- Output sequence length: 5 timesteps\n",
    "- Number of features: varies based on selection\n",
    "\n",
    "**Next step:** Model Training (06_Model_Training.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
