{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c009b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.config import RAW_DATA_PATH, CLEANED_DATA_PATH, TARGET_COLUMN, DATE_COLUMN\n",
    "from src.data_preprocessing import (\n",
    "    load_data, convert_datetime, check_missing_values,\n",
    "    handle_missing_values, handle_duplicates, handle_outliers_iqr,\n",
    "    check_time_continuity, resample_hourly, preprocess_pipeline\n",
    ")\n",
    "from src.utils import save_csv\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abf235",
   "metadata": {},
   "source": [
    "## 2.1 Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(RAW_DATA_PATH)\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41833380",
   "metadata": {},
   "source": [
    "## 2.2 Handle DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ca6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime and sort\n",
    "df = convert_datetime(df, DATE_COLUMN)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a11a87",
   "metadata": {},
   "source": [
    "## 2.3 Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates before\n",
    "print(f\"Duplicate timestamps before: {df[DATE_COLUMN].duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df = handle_duplicates(df, DATE_COLUMN, keep='first')\n",
    "\n",
    "print(f\"Shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ab9ae",
   "metadata": {},
   "source": [
    "## 2.4 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing_df = check_missing_values(df)\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Missing values found:\")\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values if any\n",
    "df = handle_missing_values(df, numerical_strategy='interpolate', categorical_strategy='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d367b",
   "metadata": {},
   "source": [
    "## 2.5 Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15991b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers before handling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].boxplot(df[TARGET_COLUMN])\n",
    "axes[0].set_title('Traffic Volume - Before Outlier Handling')\n",
    "axes[0].set_ylabel('Traffic Volume')\n",
    "\n",
    "# Handle outliers\n",
    "df = handle_outliers_iqr(df, TARGET_COLUMN, factor=1.5, method='clip')\n",
    "\n",
    "axes[1].boxplot(df[TARGET_COLUMN])\n",
    "axes[1].set_title('Traffic Volume - After Outlier Handling')\n",
    "axes[1].set_ylabel('Traffic Volume')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25697b",
   "metadata": {},
   "source": [
    "## 2.6 Check Time Continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84872d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing timestamps\n",
    "df, n_missing = check_time_continuity(df, DATE_COLUMN, freq='H')\n",
    "\n",
    "if n_missing > 0:\n",
    "    print(f\"\\nFound {n_missing} missing hourly timestamps. Resampling...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92eb327",
   "metadata": {},
   "source": [
    "## 2.7 Resample to Hourly (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75debee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to ensure hourly continuity\n",
    "df = resample_hourly(df, DATE_COLUMN, TARGET_COLUMN)\n",
    "\n",
    "print(f\"\\nFinal shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0961e8",
   "metadata": {},
   "source": [
    "## 2.8 Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate timestamps: {df[DATE_COLUMN].duplicated().sum()}\")\n",
    "print(f\"Date range: {df[DATE_COLUMN].min()} to {df[DATE_COLUMN].max()}\")\n",
    "print(f\"\\nTarget column ({TARGET_COLUMN}) statistics:\")\n",
    "print(df[TARGET_COLUMN].describe())\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cleaned data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8860e43",
   "metadata": {},
   "source": [
    "## 2.9 Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "save_csv(df, CLEANED_DATA_PATH, index=False)\n",
    "\n",
    "print(f\"\\nCleaned data saved to: {CLEANED_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179efdd3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Preprocessing steps completed:**\n",
    "1. ✅ Converted datetime column\n",
    "2. ✅ Sorted by timestamp\n",
    "3. ✅ Removed duplicate timestamps\n",
    "4. ✅ Handled missing values\n",
    "5. ✅ Handled outliers using IQR method\n",
    "6. ✅ Resampled to ensure hourly continuity\n",
    "7. ✅ Saved cleaned data\n",
    "\n",
    "**Next step:** Feature Engineering (03_Feature_Engineering.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
